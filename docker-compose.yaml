version: "3.2"

services:
  fuseki-persons:
    image: docker.io/zazuko/jena-fuseki:4.2.0-wildfly
    build:
      context: ./image/
      dockerfile: Dockerfile.wildfly

    networks:
      - application

    environment:
      OTEL_RESOURCE_ATTRIBUTES: service.name=fuseki-persons
      OTEL_TRACES_EXPORTER: otlp
      OTEL_METRICS_EXPORTER: prometheus
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector:4317"

    depends_on:
      - collector

    healthcheck:
      test:
        ["CMD-SHELL", "wget -nv -t1 --spider localhost:3030/$$/ping || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

    volumes:
      - "./data/:/data/"

    ports:
      - "8080:8080"
      - "9990:9990"

    labels:
      co.elastic.logs/enabled: "true"
      co.elastic.logs/module: "fuseki"
      co.elastic.logs/fileset: log

    logging:
      driver: json-file

  fuseki-relations:
    image: docker.io/zazuko/jena-fuseki:4.2.0
    build: ./image/
    command: >-
      --file /data/relations.nt /ds

    networks:
      - application

    environment:
      OTEL_RESOURCE_ATTRIBUTES: service.name=fuseki-relations
      OTEL_TRACES_EXPORTER: otlp
      OTEL_METRICS_EXPORTER: otlp
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector:4317"

    depends_on:
      - collector

    healthcheck:
      test:
        ["CMD-SHELL", "wget -nv -t1 --spider localhost:3030/$$/ping || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

    volumes:
      - "./data/:/data/"

    ports:
      - "3031:3030"

    labels:
      co.elastic.logs/enabled: "true"
      co.elastic.logs/module: "fuseki"
      co.elastic.logs/fileset: log

    logging:
      driver: json-file

  collector:
    image: otel/opentelemetry-collector:0.26.0
    command: >-
      --config=/collector.yaml

    networks:
      - application
      - monitoring

    depends_on:
      jaeger:
        condition: service_healthy

    volumes:
      - "./config/collector.yaml:/collector.yaml:ro"

    labels:
      co.elastic.logs/enabled: "false"

    #logging:
    #  driver: json-file

  jaeger:
    image: jaegertracing/all-in-one:1.22

    networks:
      - monitoring

    healthcheck:
      test: ["CMD-SHELL", "wget -nv -t1 --spider localhost:14269/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

    ports:
      - "16686:16686"

    labels:
      co.elastic.logs/enabled: "false"

    #logging:
    #  driver: json-file

  prometheus:
    image: prom/prometheus:v2.26.0
    command: >-
      --config.file=/prometheus.yaml
      --web.enable-lifecycle

    networks:
      - monitoring

    depends_on:
      - collector

    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -nv -t1 --spider localhost:9090/-/healthy || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

    volumes:
      - "./config/prometheus.yaml:/prometheus.yaml:ro"

    ports:
      - "9090:9090"

    labels:
      co.elastic.logs/enabled: "false"

    #logging:
    #  driver: json-file

  opensearch:
    image: opensearchproject/opensearch:1.0.0

    environment:
      node.name: opensearch
      cluster.name: opensearch
      bootstrap.memory_lock: "true"
      discovery.type: single-node
      ES_JAVA_OPTS: -Xms2G -Xmx2G

    ulimits:
      memlock:
        soft: -1
        hard: -1

    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --silent --fail https://localhost:9200/_cluster/health --insecure -u admin:admin || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

    ports:
      - "9200:9200"

    networks:
      - elastic

    labels:
      co.elastic.logs/enabled: "false"
      co.elastic.logs/module: "elasticsearch"

    #logging:
    #  driver: json-file

  filebeat:
    image: docker.elastic.co/beats/filebeat-oss:7.12.1
    user: root

    depends_on:
      opensearch:
        condition: service_healthy
      opensearch-dashboards:
        condition: service_healthy

    command: >-
      -e
      --strict.perms=false

    environment:
      ELASTICSEARCH_HOST: 'https://opensearch:9200'
      KIBANA_HOST: opensearch-dashboards:5601

    volumes:
      - ./config/filebeat.yaml:/usr/share/filebeat/filebeat.yml:ro
      - ./filebeat-module:/usr/share/filebeat/module/fuseki:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/containers/:/var/lib/docker/containers/:ro

    networks:
      - elastic

    labels:
      co.elastic.logs/enabled: "false"

    #logging:
    #  driver: json-file

  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:1.0.0

    depends_on:
      opensearch:
        condition: service_healthy

    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --silent --fail localhost:5601/api/status || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

    labels:
      co.elastic.logs/enabled: "false"
      co.elastic.logs/module: "kibana"

    #logging:
    #  driver: json-file

    networks:
      - elastic

    ports:
      - "5601:5601"

    environment:
      OPENSEARCH_HOSTS: '["https://opensearch:9200"]'

  grafana:
    image: grafana/grafana:7.5.6
    ports:
      - "3000:3000"

    environment:
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: Admin

    networks:
      - monitoring
      - elastic

    volumes:
      - ./config/grafana:/etc/grafana/provisioning:ro

    healthcheck:
      test:
        ["CMD-SHELL", "wget -nv -t1 --spider localhost:3000/api/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

    labels:
      co.elastic.logs/enabled: "false"

    #logging:
    #  driver: json-file

networks:
  monitoring:
  elastic:
  application:
